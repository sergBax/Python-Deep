{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgyxAMQ25SsF"
   },
   "source": [
    "Давайте создадим простую нейронную сеть, которая будет классифицировать набор данных о цветках ириса. Ниже приведен блок кода для создания простой нейронной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LGwJJgnY5FJ-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n",
    "\n",
    "dataset['species'] = pd.Categorical(dataset['species']).codes\n",
    "\n",
    "dataset = dataset.sample(frac=1, random_state=1234)\n",
    "\n",
    "# split the data set into train and test subsets\n",
    "train_input = dataset.values[:120, :4]\n",
    "train_target = dataset.values[:120, 4]\n",
    "\n",
    "test_input = dataset.values[120:, :4]\n",
    "test_target = dataset.values[120:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhvYzopj5Sl4"
   },
   "source": [
    "Предыдущий код представляет собой стандартный код, который загружает CSV-файл набора данных Iris, а затем загружает его во фрейм данных pandas. Затем мы перетасовываем строки фрейма данных и разбиваем код на массивы numpy, train_input/train_target (свойства цветка/класс цветка) для обучающих данных и test_input/test_target для тестовых данных. \n",
    "Мы будем использовать 120 образцов для обучения и 30 для тестирования. Если вы не знакомы с pandas, думайте об этом как о продвинутой версии NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pccpZgHU8iAB"
   },
   "source": [
    "Давайте определим нашу первую нейронную сеть. Мы будем использовать сеть прямой связи с одним скрытым слоем с пятью блоками, функцию активации ReLU (это просто другой тип активации, определяемый просто как *f(x) = max(0, x)*) и выходной слой с тремя блоками. Выходной слой состоит из трех блоков, причем каждый блок соответствует одному из трех классов цветка ириса. Ниже приведено определение высоты тона сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_dOD1OMg8knA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "hidden_units = 5\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, hidden_units), # we'll use a network with 4 hidden units\n",
    "    torch.nn.ReLU(), # ReLU activation\n",
    "    torch.nn.Linear(hidden_units, 3) # 3 output units for each of the 3 possible classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri9tmJd_87qB"
   },
   "source": [
    "Мы будем использовать однократное кодирование для целевых данных. Это означает, что каждый класс цветка будет представлен в виде массива (Iris Setosa = [1, 0, 0], Iris Versicolour = [0, 1, 0] и Iris Virginica = [0, 0, 1]), и один элемент массива будет целевым для одной единицы выходного слоя. Когда сеть классифицирует новый образец, мы определяем класс, беря единицу с наибольшим значением активации. \n",
    "`torch.manual_seed(1234)` позволяет нам каждый раз использовать одни и те же случайные данные для воспроизводимости результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iMaXLyq-ES2"
   },
   "source": [
    "Далее мы выберем функцию потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SiqLpoz6-Ic9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv7_EwIu-SGs"
   },
   "source": [
    "С помощью переменной `criterion` мы определяем функцию потерь, которую будем использовать, в данном случае это кросс-энтропийные потери. Функция потерь будет измерять, насколько выходные данные сети отличаются от целевых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFxHfeDl-ZLC"
   },
   "source": [
    "Затем мы определяем оптимизатор стохастического градиентного спуска (SGD) (вариация алгоритма градиентного спуска) со скоростью обучения 0,1 и импульсом 0,9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iCGhvKK0-5DT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RV5Wiw3k_FDI"
   },
   "source": [
    "Теперь давайте обучим сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRkD7513_I9i",
    "outputId": "ca3ee637-fc47-4e44-ceea-6791b95ca248",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.2181\n",
      "Epoch 10 Loss: 0.6745\n",
      "Epoch 20 Loss: 0.2447\n",
      "Epoch 30 Loss: 0.1397\n",
      "Epoch 40 Loss: 0.1001\n",
      "Epoch 50 Loss: 0.0855\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    inputs = torch.autograd.Variable(torch.Tensor(train_input).float())\n",
    "    targets = torch.autograd.Variable(torch.Tensor(train_target).long())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = net(inputs)\n",
    "    loss = criterion(out, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        print('Epoch %d Loss: %.4f' % (epoch + 1, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqVJH4UU_SH-"
   },
   "source": [
    "Мы проведем обучение в течение 50 эпох, что означает, что мы выполним итерацию 50 раз по набору обучающих данных: \n",
    "\n",
    "\n",
    "1. Создайте переменные torch, которые являются `input` и `target`, из массивов numpy train_input и train_target. \n",
    "2. Обнулите градиенты оптимизатора, чтобы предотвратить накопление результатов предыдущих итераций. Мы передаем обучающие данные в сеть нейронной сети (входные данные) и вычисляем критерий функции потерь (выход, цели) между выходными данными сети и целевыми данными.\n",
    "3. Передайте значение потерь обратно по сети. Мы делаем это для того, чтобы можно было рассчитать, как вес каждой сети влияет на функцию потерь. \n",
    "4. Оптимизатор обновляет веса сети таким образом, чтобы уменьшить будущие значения функции потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVfDIxE6AJpC"
   },
   "source": [
    "Давайте посмотрим, какова конечная точность нашей модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13bt21qAALGI",
    "outputId": "012148f3-d2ba-443f-fe17-a41d71c77661",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 0; Accuracy: 100%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = torch.autograd.Variable(torch.Tensor(test_input).float())\n",
    "targets = torch.autograd.Variable(torch.Tensor(test_target).long())\n",
    "\n",
    "optimizer.zero_grad()\n",
    "out = net(inputs)\n",
    "_, predicted = torch.max(out.data, 1)\n",
    "\n",
    "error_count = test_target.size - np.count_nonzero((targets == predicted).numpy())\n",
    "print('Errors: %d; Accuracy: %d%%' % (error_count, 100 * torch.sum(targets == predicted) / test_target.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
